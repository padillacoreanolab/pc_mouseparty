"""Main module."""


import os
import re
import operator
import traceback
import warnings
import pathlib
import h5py
import math
import numpy as np
import pandas as pd
import moviepy.editor as mpy
from moviepy.editor import *
from medpc2excel.medpc_read import medpc_read
from scipy.interpolate import interp1d
from scipy.signal import savgol_filter
from collections import defaultdict


def get_all_animal_ids(animal_string):
    """
    Converts a string that contains the ID of animals, and only gets the IDs.
    This usually removes extra characters that were added.
    (i.e. "1.1 v 2.2" to ("1.1", "2.2"))

    Args:
        animal_string(str): This is the first param.

    Returns:
        tuple: Of IDs of animals as strings
    """
    # Splitting by space so that we have a list of just the words
    all_words = animal_string.split()
    # Removing all words that are not numbers
    all_numbers = [num for num in all_words if re.match(r'^-?\d+(?:\.\d+)$', num)]
    return tuple(all_numbers)


def add_session_number_column(
    dataframe,
    indexes,
    session_number_column="session_number"
):
    """
    Add a column to Pandas DataFrame that contains the session number.
    This will only add session numbers to the rows specified by indexes.
    You can fill in the empty cells with method:
    DataFrame.fillna(method='ffill')

    Args:
        dataframe(Pandas DataFrame): The DataFrame to add the
        session number column
        indexes(list): List of indexes for which rows to
        add the session numbers
        session_number_column(str): Name of the column to add

    Returns:
        Pandas DataFrame: DataFrame with the session numbers added
    """
    copy_dataframe = dataframe.copy()
    session_number = 1
    for index in indexes:
        copy_dataframe.at[index, session_number_column] = session_number
        session_number += 1
    return copy_dataframe


def scale_time_to_whole_number(time, multiplier=100):
    """
    Function used to convert times that are floats into whole numbers
    by scaling it. i.e. from 71.36 to 7136
    This is used with pandas.DataFrame.apply/pandas.Series.apply
    to convert a column of float times to integer times.

    Args:
        time: float
            - The time in seconds that something is happening
    Returns:
        int:
            - Converted whole number time
    """
    try:
        if np.isnan(time):
            return 0
        else:
            return int(time * multiplier)
    except Exception:
        return 0
    

def parse_exported_file(file_path):
    """
    """
    with open(file_path, 'rb') as f:
        # Check if first line is start of settings block
        if f.readline().decode('ascii').strip() != '<Start settings>':
            raise Exception("Settings format not supported")
        fields = True
        fields_text = {}
        for line in f:
            # Read through block of settings
            if fields:
                line = line.decode('ascii').strip()
                # filling in fields dict
                if line != '<End settings>':
                    vals = line.split(': ')
                    fields_text.update({vals[0].lower(): vals[1]})
                # End of settings block, signal end of fields
                else:
                    fields = False
                    dt = parse_fields(fields_text['fields'])
                    fields_text['data'] = np.zeros([1], dtype=dt)
                    break
        # Reads rest of file at once, using dtype format
        # generated by parse_fields()
        dt = parse_fields(fields_text['fields'])
        data = np.fromfile(f, dt)
        fields_text.update({'data': data})
        return fields_text
    

# Parses last fields parameter (<time uint32><...>) as a single string
# Assumes it is formatted as <name number * type> or <name type>
# Returns: np.dtype
def parse_fields(field_str):
    """
    """
    # Returns np.dtype from field string
    sep = re.split('\s', re.sub(r"\>\<|\>|\<", ' ', field_str).strip())
    # print(sep)
    typearr = []
    # Every two elmts is fieldname followed by datatype
    for i in range(0, sep.__len__(), 2):
        fieldname = sep[i]
        repeats = 1
        ftype = 'uint32'
        # Finds if a <num>* is included in datatype
        if sep[i+1].__contains__('*'):
            temptypes = re.split('\*', sep[i+1])
            # Results in the correct assignment,
            # whether str is num*dtype or dtype*num
            ftype = temptypes[temptypes[0].isdigit()]
            repeats = int(temptypes[temptypes[1].isdigit()])
        else:
            ftype = sep[i+1]
        try:
            fieldtype = getattr(np, ftype)
        except AttributeError:
            print(ftype + " is not a valid field type.\n")
            exit(1)
        else:
            typearr.append((str(fieldname), fieldtype, repeats))
    return np.dtype(typearr)


def get_key_with_substring(input_dict, substring="", return_first=True):
    """
    """
    keys_with_substring = []
    for key in input_dict.keys():
        if substring in key:
            keys_with_substring.append(key)
    if substring in keys_with_substring:
        return substring
    elif return_first:
        return keys_with_substring[0]
    else:
        return keys_with_substring
    

def get_all_file_suffixes(file_name):
    """
    Creates a string of the suffixes of a file
    name that's joined together by "."
    Suffixes will be all the parts of the file name that follows the first "."
    Example: "file.txt.zip.asc" >> "txt.zip.asc"

    Args:
        file_name(str): Name of the file

    Returns:
        String of all the suffixes joined by "."
    """
    # Getting all the suffixes in the file name
    # And removing any periods before and after
    stripped_suffixes = [
        suffix.strip(".") for suffix in pathlib.Path(file_name).suffixes
        ]

    if stripped_suffixes:
        return ".".join(stripped_suffixes)
    # When the file name is just a ".", the stripped suffix is blank
    else:
        return "."
    

def fill_missing(Y, kind="linear"):
    """
    Fills missing values independently along each dimension
    after the first.
    """

    # Store initial shape.
    initial_shape = Y.shape

    # Flatten after first dim.
    Y = Y.reshape((initial_shape[0], -1))

    # Interpolate along each slice.
    for i in range(Y.shape[-1]):
        y = Y[:, i]

        # Build interpolant.
        x = np.flatnonzero(~np.isnan(y))
        f = interp1d(x, y[x], kind=kind, fill_value=np.nan, bounds_error=False)

        # Fill missing
        xq = np.flatnonzero(np.isnan(y))
        y[xq] = f(xq)

        # Fill leading or trailing NaNs with the nearest non-NaN values
        mask = np.isnan(y)
        y[mask] = np.interp(
            np.flatnonzero(mask),
            np.flatnonzero(~mask),
            y[~mask]
            )

        # Save slice
        Y[:, i] = y

    # Restore to initial shape.
    Y = Y.reshape(initial_shape)

    return Y